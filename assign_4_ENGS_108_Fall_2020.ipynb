{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assign_4_ENGS_108_Fall_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1EXaYP-OTNO9eltRbwKEkUondRH_HxZgx",
      "authorship_tag": "ABX9TyM7eeVmWzLawa3QmheqxMX+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yakaboskic/ENGS_108_Fall_2020/blob/master/assign_4_ENGS_108_Fall_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BiHNk7HcRiL"
      },
      "source": [
        "# **ENGS 108 Fall 2020 Assignment 4**\n",
        "\n",
        "*Due October 21, 2020 at 11:59PM on Canvas*\n",
        "\n",
        "**Instructors:** George Cybenko\n",
        "\n",
        "**TAs:** Chase Yakaboski\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## **Rules and Requirements**\n",
        "\n",
        "\n",
        "1.   You are only allowed to use Python packages that are explicity imported in \n",
        "the assignment notebook or are standard (bultin) python libraries like random, os, sys, etc, (Standard Bultin Python libraries will have a Python.org documentation). For this assignment you may use:\n",
        "  *   [numpy](https://numpy.org/doc/stable/)\n",
        "  *   [pandas](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
        "  *   [scikit-learn](https://scikit-learn.org/stable/)\n",
        "  *   [matplotlib](https://matplotlib.org/)\n",
        "  *   [tensorflow](https://www.tensorflow.org/)\n",
        "\n",
        "2.   All code must be fit into the designated code or text blocks in the assignment notebook. They are indentified by a **TODO** qualifier.\n",
        "\n",
        "3. For analytical questions that don't require code, type your answer cleanly in Markdown. For help, see the [Google Colab Markdown Guide](https://colab.research.google.com/notebooks/markdown_guide.ipynb).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KqjPtWlcFnS"
      },
      "source": [
        "''' Import Statements '''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import copy\n",
        "import pickle\n",
        "import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwDQkydPckQx"
      },
      "source": [
        "## **Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk-tVmSXco2Y"
      },
      "source": [
        "dataset_base_path = '/content/sample_data'\n",
        "\n",
        "#TODO: Set your base datasets path. This is my base path, you will need to change to match yours. \n",
        "dataset_github_path = '/content/drive/My Drive/git/ENGS_108_Fall_2020/datasets'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_duATmD4cvjb"
      },
      "source": [
        "#-- Load circles dataset, format is X, y where X is a 2 dimensional coordinate and y is the label.\n",
        "with open(os.path.join(dataset_github_path, 'circles.pk'), 'rb') as f_:\n",
        "  circles = pickle.load(f_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0otRQ4_CcxP4"
      },
      "source": [
        "## **Problem 1: Support Vector Machines**\n",
        "In this problem, you will be building a support vector machines to for both regression and classification tasks.\n",
        ">\n",
        "> **Part 1** In this part we will be exploring the *circles* dataset. In this dataset you will have an $X$ array of 2 dimensional samples of the form $(x_1, x_2)$ and a $y$ array of each samples associated label. \n",
        ">> **(a)** Go through the circles dataset and create a scatterplot of the circles data using the y label of each samples color to designate their respective class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0x9dZvokiNb"
      },
      "source": [
        "X, y = circles\n",
        "#TODO: Your code goes here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgvLE0AkmY25"
      },
      "source": [
        ">> **(b)** Is this dataset linearly seperable? Explain why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeENaqJ1mj7w"
      },
      "source": [
        "**TODO:** Your answer should go here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEdDW9SFm8iQ"
      },
      "source": [
        ">> **(c)** Can you think of a transformation of the dataset that could make the dataset linearly seperable? If so, define what these transformation function(s) might look like, and if not explain why. *Hint: Think of a higher dimensional space.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYglGeG2nb0J"
      },
      "source": [
        "**TODO:** Your answer should go here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju6WgDvvoHm1"
      },
      "source": [
        ">> **(d)** If you where able to find a transformation in (c), create a suitable graph showing the dataset is linearly seperable in this new feature space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRj9ixOMoFck"
      },
      "source": [
        "#TODO: Your code goes here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2_By96Aqn1r"
      },
      "source": [
        "> **Part 2** What we accomplished in Part 1 is known as the kernel trick for SVMs. Now let's focus on how we can use this idea to accomplish non-linear classification on a real world dataset. In this next part and throughout the remainder of the assignment we will be using a food image dataset. These images are RGB images of many pixels. \n",
        ">> **(a)** You have been given a number of code skeletons throughout the course all of which load and preprocess the data for you. In this excerise tho, we will be doing the data loading manually as it is an important skill to learn. Write some code that will walk through the *ExampleFoodImageDataset* directory structure and build a single large numpy array with all image features flattened into a large vector (Make sure to resize the image to something like (28, 28) or (32, 32), etc.) the first column being a integer id for the class. *Hint: You have been provided with a basic skeleton, study the operations of the code and finish the script.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbPRTcGMozJR"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "#-- The dimensions of the resized image\n",
        "RESIZE = (28,28)\n",
        "#-- A map from integer ids to food categories (strings)\n",
        "food_map = {}\n",
        "#-- The data list that we will be filling in.\n",
        "data = []\n",
        "#-- The folder that the food images are in\n",
        "folder = os.path.join(dataset_github_path, 'ExampleFoodImageDataset')\n",
        "\n",
        "#-- Let's start our for loop (Just using tqdm to give us a pretty progress bar).\n",
        "for idx, subfold in enumerate(tqdm.tqdm(os.listdir(folder), desc='Processing images', leave=False)):                                                                             \n",
        "  if os.path.isdir(os.path.join(folder, subfold)):\n",
        "    #-- We have found image class folder so let's extract all example data\n",
        "    map_[idx] = subfold\n",
        "    for img_name in os.listdir(os.path.join(folder, subfold)):\n",
        "      #-- Make sure the file is an image\n",
        "      if img_name.endswith('.jpg'):\n",
        "        #TODO: You do this part. Use the Image class from PIL to load the image and cast it into a np array.\n",
        "        #TODO: Then make sure to resize the image (otherwise things will take awhile)\n",
        "\n",
        "data = np.array(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qADfvsX72Cv3"
      },
      "source": [
        ">> **(b)** Split your dataset into training and testing sets with an 80/20 split. *Hint: Look at Sklearn's train_test_split function.* Then implement a SVM classifer and report your accuracy on the testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKe1O14izgqt"
      },
      "source": [
        "#TODO: Your code goes here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87teUag73uZQ"
      },
      "source": [
        ">> **(c)** Choose a 2 hyperparameters to study and experiment with. Can you make an SVM that has better accuracy then just using the defaults?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1HpNC_4h4u"
      },
      "source": [
        "#TODO: Your code goes here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVxn8HdM5TcW"
      },
      "source": [
        "## **Problem 2: Introduction to TensorFlow**\n",
        "In this problem, we will start working in tensorflow to build deep learning systems starting with fully connected neural networks. We will focus on using the food image dataset we built in the last problem.\n",
        ">\n",
        "> **(a)** Using the food image dataset we built in the last problem, build a [tensorflow Data Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) that is shuffled with a batch size of 10. *Hint: We did this in class.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBdJhl5w6j_G"
      },
      "source": [
        "#TODO: Your code goes here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX3A4fbs67fV"
      },
      "source": [
        "> **(b)** Build a two layer fully connected neural network of any size with a ReLu activation function and a final softmax layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9LRLfCx76pH"
      },
      "source": [
        "#TODO: Your code goes here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8F3cCyv7dqW"
      },
      "source": [
        "> **(c)** Compile your model with an appropriate loss function and optimizer. Briefly describe your choices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1HVghoH7_sV"
      },
      "source": [
        "#TODO: Your code goes here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMlYa9Q774fc"
      },
      "source": [
        "> **(d)** Train your model on the food image training dataset. And report your accuracy on the testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNAa8bsO9jy8"
      },
      "source": [
        "#TODO: Your code goes here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c50PwpT9sO4"
      },
      "source": [
        "> **(e)** Now try to tune this network by varying the number of layers, units, activations and see if you can outperform the network in part (d). Does your best model perform better or worse than the SVM in problem 1?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz9IiBaF8gb1"
      },
      "source": [
        "#TODO: Your code goes here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Ozegh2-MAX"
      },
      "source": [
        "> **(BONUS)** We lost a lot of information when we resized the images in part (a). What would happen if we didn't resize the images and we built fit the neural network with all this other information? Try it out! *Hint: Runtime will be much longer, both to create the image dataset without resizing and to train the model, so you might have to get the code working and then just let it run.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qxOwzDD-KjU"
      },
      "source": [
        "#TODO: Your code goes here."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}